<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Kang-wook Kim</title>
  
  <meta name="author" content="Kang-wook Kim">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/kwkim_pic.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Kang-wook Kim</name>
              </p>
              <p>
                Hello, I am currently an undergraduate student majoring in Electrical and Computer Engineering at Seoul National University.
		At present, I am an intern at the <a href="https://list.snu.ac.kr/">Laboratory for Imaging Science and Technology (LIST)</a>, conducting research on bio imaging using deep learning.
	      </p>
	      <p>
	      My past experiences include a research internship at <a href="https://supertone.ai/">Supertone Inc.</a> focusing on voice recognition, and a senior research scientist role at <a href="https://maum.ai/">MINDsLab Inc.</a>, where I specialized in speech synthesis.
              </p>
	      <p>
	        I am eager to pursue a Ph.D. degree abroad.
	      </p>
              <!-- <p>
                At Google I've worked on <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://www.google.com/get/cardboard/jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, <a href="https://www.youtube.com/watch?v=JSnB06um5r4">Glass</a>, and <a href="https://www.matthewtancik.com/nerf">NeRF</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I've received the <a href="https://www2.eecs.berkeley.edu/Students/Awards/15/">C.V. Ramamoorthy Distinguished Research Award</a> and the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>.
              </p> -->
              <p style="text-align:center">
                <a href="mailto:full324@snu.ac.kr">Email</a> &nbsp/&nbsp
                <a href="data/kwkim_cv.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=DZ08mDcAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.semanticscholar.org/author/Kang-Wook-Kim/33905162">Semantic Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/KangwookKim1">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/wookladin">Github</a> &nbsp/&nbsp
                <a href="https://linkedin.com/in/kang-wook-kim-1aa772224">Linkedin</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/kwkim_pic.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/kwkim_pic.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research focus is on speech synthesis and deep learning, with a particular emphasis on analyzing and manipulating speech. Some of my notable papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/fs-ncsr.png" alt="clean-usnob" width="160" height="106">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2204.09679">
                <papertitle>FS-NCSR: Increasing Diversity of the Super-Resolution Space via Frequency Separation and Noise-Conditioned Normalizing Flow
                </papertitle>
              </a>
              <br>
              Ki-Ung Song*, Dongseok Shim*, <strong>Kang-wook Kim*</strong>, Jae-young Lee, Younggeun Kim
              <br>
							<em>NTIRE CVPRW, 2022</em>
              <br>
              <a href="https://arxiv.org/abs/2204.09679">arXiv</a>
              <!-- /
              <a href="https://youtu.be/zBSH-k9GbV4">video</a> -->
              <p></p>
              <p><strong>2nd place</strong> on the <em>NTIRE Learning Super-Resolution Space Challenge</em> 4X track and <strong>1st place</strong> on the 8X track.</p>
            </td>
          </tr> 

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/multilingual.png" alt="clean-usnob" width="160" height="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2205.06421">
                  <papertitle>Talking Face Generation with Multilingual TTS
                  </papertitle>
                </a>
                <br>
                Hyoung-Kyu Song*, Sang Hoon Woo*, Junhyeok Lee, Seungmin Yang, Hyunjae Cho, Youseong Lee, Dongho Choi, <strong>Kang-wook Kim</strong>
                <br>
                <em>CVPR Demo Track (Round 1), 2022</em>
                <br>
                <a href="https://arxiv.org/abs/2205.06421">arXiv</a>
                /
                <a href="https://bit.ly/ml-face-generation-cvpr22-demo">Demo</a>
                <p></p>
                </td>
            </tr> 

          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/overall_assem_vc.png" alt="clean-usnob" width="160" height="160">
            </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2104.00931">
                  <papertitle>Assem-VC: Realistic Voice Conversion by Assembling Modern Speech Synthesis Techniques</papertitle>
                </a>
                <br>
                <strong>Kang-wook Kim</strong>,
                <a href="https://swpark.me/">Seung-won Park</a>,
                Junhyeok Lee,
                Myun-chul Joe
                <br>
                To appear in <em>Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2022</em>
                <br>
                <a href="https://maum-ai.github.io/assem-vc/">project page</a>
                /
                <a href="https://arxiv.org/abs/2104.00931">arXiv</a>
                /
                <a href="https://github.com/maum-ai/assem-vc">github</a>
          <!-- /
                <a href="https://youtu.be/qrdRH9irAlk">video</a> -->
                <p></p>
                <p></p>
              </td>
            </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/assem_singer.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2110.12676">
                <papertitle>Controllable and Interpretable Singing Voice Decomposition via Assem-VC</papertitle>
              </a>
              <br>
              <strong>Kang-wook Kim</strong>,
              Junhyeok Lee
              <br>
							<em>NeurIPS Workshop on ML for Creativity and Design, 2021</em> &nbsp <font color="red"><strong>(Oral Presentation [top 6.2%])</strong></font>
              <br>
              <a href="https://maum-ai.github.io/assem-vc/singer/">project page</a>
              /
              <a href="https://arxiv.org/abs/2110.12676">arXiv</a>
              /
              <a href="https://github.com/maum-ai/assem-vc">github</a>
              /
              <a href="data/ml4cd2021.bib">bibtex</a>
              <!-- /
              <a href="https://youtu.be/zBSH-k9GbV4">video</a> -->
              <p></p>
              <p>We propose a controllable singing decomposition system that encodes time-aligned linguistic content, pitch, and source speaker identity via Assem-VC.</p>
            </td>
          </tr> 

    </tbody></table>


</body>

</html>
